{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['nv_list', 'num_steps', 'num_reps', 'num_runs', 'uwave_ind', 'uwave_freq', 'num_exps_per_rep', 'load_iq', 'step_ind_master_list', 'counts-units', 'counts', 'states', 'timestamp', 'config', 'opx_config'])\n",
      "Number of NVs: 10\n",
      "Coordinates (Pixel): [58.628, 139.616]\n",
      "Coordinates (Pixel): [137.025, 74.662]\n",
      "Coordinates (Pixel): [170.501, 132.597]\n",
      "Coordinates (Pixel): [171.074, 49.877]\n",
      "Coordinates (Pixel): [173.93, 78.505]\n",
      "Coordinates (Pixel): [144.169, 163.787]\n",
      "Coordinates (Pixel): [110.023, 87.942]\n",
      "Coordinates (Pixel): [135.139, 104.013]\n",
      "Coordinates (Pixel): [161.477, 105.335]\n",
      "Coordinates (Pixel): [131.144, 129.272]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load data from JSON file\n",
    "file_path = '../data/raw/2024_05_27-04_37_40-johnson-nv0_2024_03_12.txt'\n",
    "with open(file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Print the keys in the JSON data\n",
    "print(data.keys())\n",
    "\n",
    "# Accessing NV List and Keys\n",
    "nv_list = data['nv_list']\n",
    "print(f\"Number of NVs: {len(nv_list)}\")\n",
    "\n",
    "# Accessing Coordinates of NVs\n",
    "for nv in nv_list:\n",
    "    print(f\"Coordinates (Pixel): {nv['coords']['pixel']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Process counts and states\n",
    "counts = np.array(data[\"counts\"])\n",
    "states = np.array(data[\"states\"])\n",
    "num_runs = counts.shape[2]\n",
    "\n",
    "start, window = 1000, 500\n",
    "counts = counts[:, :, start:start + window, :, :]\n",
    "states = states[:, :, start:start + window, :, :]\n",
    "\n",
    "exclude_inds = ()\n",
    "num_nvs = len(nv_list)\n",
    "nv_list = [nv_list[ind] for ind in range(num_nvs) if ind not in exclude_inds]\n",
    "num_nvs = len(nv_list)\n",
    "counts = np.delete(counts, exclude_inds, axis=1)\n",
    "\n",
    "# Break down the counts array\n",
    "sig_counts = np.array(counts[0])\n",
    "ref_counts = np.array(counts[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to compute correlation matrix\n",
    "# def compute_correlation_matrix(binary_counts):\n",
    "#     return np.corrcoef(binary_counts)\n",
    "\n",
    "# # Function to adjust threshold values to minimize correlation in reference data\n",
    "# def adjust_thresholds(ref_counts, thresh_vals, lr=0.001, max_iter=1000, tol=1e-10):\n",
    "#     for iter in range(max_iter):\n",
    "#         bin_ref_counts = np.where(ref_counts > thresh_vals[:, None, None, None], 1, 0)\n",
    "#         corr_matrix_ref = compute_correlation_matrix(bin_ref_counts.reshape(num_nvs, -1))\n",
    "#         avg_corr = np.mean(np.abs(corr_matrix_ref[np.triu_indices(num_nvs, k=1)]))\n",
    "\n",
    "#         if avg_corr < tol:\n",
    "#             print(f\"Convergence reached at iteration {iter} with average correlation {avg_corr}\")\n",
    "#             break\n",
    "\n",
    "#         gradient = np.sum(corr_matrix_ref, axis=1) - np.diag(corr_matrix_ref)\n",
    "#         thresh_vals -= lr * gradient\n",
    "\n",
    "#     return thresh_vals\n",
    "# Function to compute correlation matrix\n",
    "def compute_correlation_matrix(binary_counts):\n",
    "    return np.corrcoef(binary_counts)\n",
    "\n",
    "# Improved function to adjust threshold values to minimize correlation in reference data\n",
    "def adjust_thresholds(ref_counts, thresh_vals, lr=0.001, beta=0.3, max_iter=1000, tol=1e-10):\n",
    "    velocity = np.zeros_like(thresh_vals)\n",
    "    for iter in range(max_iter):\n",
    "        bin_ref_counts = np.where(ref_counts > thresh_vals[:, None, None, None], 1, 0)\n",
    "        corr_matrix_ref = compute_correlation_matrix(bin_ref_counts.reshape(num_nvs, -1))\n",
    "        avg_corr = np.mean(np.abs(corr_matrix_ref[np.triu_indices(num_nvs, k=1)]))\n",
    "\n",
    "        if avg_corr < tol:\n",
    "            print(f\"Convergence reached at iteration {iter} with average correlation {avg_corr}\")\n",
    "            break\n",
    "\n",
    "        gradient = np.sum(corr_matrix_ref, axis=1) - np.diag(corr_matrix_ref)\n",
    "        velocity = beta * velocity + (1 - beta) * gradient\n",
    "        thresh_vals -= lr * velocity\n",
    "\n",
    "        # Ensure thresholds stay within a valid range\n",
    "        thresh_vals = np.clip(thresh_vals, np.min(ref_counts), np.max(ref_counts))\n",
    "\n",
    "    return thresh_vals\n",
    "# Placeholder function for threshold_counts (needs proper definition based on your context)\n",
    "def threshold_counts(nv_list, sig_counts, ref_counts, dynamic_thresh=True):\n",
    "    if dynamic_thresh:\n",
    "        initial_thresholds = np.array([nv['threshold'] for nv in data['nv_list']])\n",
    "        thresholds = adjust_thresholds(ref_counts, initial_thresholds)\n",
    "        sig_counts = np.where(sig_counts > thresholds[:, None, None, None], 1, 0)\n",
    "        ref_counts = np.where(ref_counts > thresholds[:, None, None, None], 1, 0)\n",
    "    return sig_counts, ref_counts\n",
    "\n",
    "# Adjust thresholds and calculate correlations\n",
    "sig_counts, ref_counts = threshold_counts(nv_list, sig_counts, ref_counts, dynamic_thresh=True)\n",
    "\n",
    "flattened_sig_counts = [sig_counts[ind].flatten() for ind in range(num_nvs)]\n",
    "flattened_ref_counts = [ref_counts[ind].flatten() for ind in range(num_nvs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_corr_coeffs = np.corrcoef(flattened_sig_counts)\n",
    "ref_corr_coeffs = np.corrcoef(flattened_ref_counts)\n",
    "\n",
    "diff_corr_coeffs = np.cov(flattened_sig_counts) - np.cov(flattened_ref_counts)\n",
    "\n",
    "spin_flips = np.array([-1 if nv.get('spin_flip', False) else +1 for nv in nv_list])\n",
    "ideal_sig_corr_coeffs = np.outer(spin_flips, spin_flips).astype(float)\n",
    "\n",
    "# Replace diagonals with nan\n",
    "vals = [sig_corr_coeffs, diff_corr_coeffs, ref_corr_coeffs, ideal_sig_corr_coeffs]\n",
    "for val in vals:\n",
    "    np.fill_diagonal(val, np.nan)\n",
    "\n",
    "print(np.nanmean(ref_corr_coeffs) / np.nanmean(np.abs(sig_corr_coeffs)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Define the output directory\n",
    "output_dir = '../data/correlation_matrix'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Save correlation matrices\n",
    "np.save(os.path.join(output_dir, 'diff_corr_coeffs.npy'), diff_corr_coeffs)\n",
    "# np.save(os.path.join(output_dir, 'correlation_matrix_signal.npy'), correlation_matrix_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "def plot_correlation_matrices(vals, titles, cbar_maxes):\n",
    "    figs = []\n",
    "    for ind in range(len(vals)):\n",
    "        fig, ax = plt.subplots()\n",
    "        cax = ax.matshow(\n",
    "            vals[ind],\n",
    "            cmap=\"RdBu_r\",\n",
    "            norm=TwoSlopeNorm(vmin=-cbar_maxes[ind], vcenter=0, vmax=cbar_maxes[ind]),\n",
    "        )\n",
    "        fig.colorbar(cax)\n",
    "        ax.set_title(titles[ind])\n",
    "        ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "        # Replace NaNs with gray color\n",
    "        data = np.ma.masked_invalid(vals[ind])\n",
    "        cmap = plt.cm.RdBu_r\n",
    "        cmap.set_bad(color='gray')\n",
    "        cax = ax.matshow(data, cmap=cmap, norm=TwoSlopeNorm(vmin=-cbar_maxes[ind], vcenter=0, vmax=cbar_maxes[ind]))\n",
    "\n",
    "        figs.append(fig)\n",
    "    \n",
    "    return figs\n",
    "\n",
    "# Example usage:\n",
    "vals = [sig_corr_coeffs, diff_corr_coeffs, ref_corr_coeffs, ideal_sig_corr_coeffs]\n",
    "titles = [\"Signal\", \"Difference\", \"Reference\", \"Ideal signal\"]\n",
    "cbar_maxes = [np.nanmax(np.abs(sig_corr_coeffs)), np.nanmax(np.abs(diff_corr_coeffs)), np.nanmax(np.abs(ref_corr_coeffs)), 1]\n",
    "\n",
    "figures = plot_correlation_matrices(vals, titles, cbar_maxes)\n",
    "\n",
    "# Display all generated plots\n",
    "for fig in figures:\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load data from JSON file\n",
    "file_path = '../data/raw/2024_05_27-04_37_40-johnson-nv0_2024_03_12.txt'\n",
    "with open(file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "# Print the keys in the JSON data\n",
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Accessing NV List and Keys\n",
    "nv_list = data['nv_list']\n",
    "print(f\"Number of NVs: {len(nv_list)}\")\n",
    "\n",
    "# Example: Accessing Coordinates of NVs\n",
    "for nv in nv_list:\n",
    "    # print(f\"NV Name: {nv['name']}\")\n",
    "    print(f\"Coordinates (Pixel): {nv['coords']['pixel']}\")\n",
    "    # print(f\"Coordinates (Global): {nv['coords']['global']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute binary counts with thresholding\n",
    "def apply_thresholding(counts, thresholds):\n",
    "    return np.where(counts > thresholds[:, None], 1, 0)\n",
    "\n",
    "# Iteratively adjust threshold values to minimize correlation in reference data\n",
    "def adjust_thresholds(reference_counts, threshold_values, learning_rate=0.01, max_iterations=1000, tolerance=1e-6):\n",
    "    for iteration in range(max_iterations):\n",
    "        binary_reference_counts = apply_thresholding(reference_counts, threshold_values)\n",
    "        correlation_matrix_reference = compute_correlation_matrix(binary_reference_counts)\n",
    "        avg_correlation = np.mean(np.abs(correlation_matrix_reference[np.triu_indices(num_nvs, k=1)]))\n",
    "\n",
    "        if avg_correlation < tolerance:\n",
    "            print(f\"Convergence reached at iteration {iteration} with average correlation {avg_correlation}\")\n",
    "            break\n",
    "\n",
    "        # Adjust thresholds based on correlation matrix\n",
    "        gradient = np.sum(correlation_matrix_reference, axis=1) - np.diag(correlation_matrix_reference)\n",
    "        threshold_values -= learning_rate * gradient\n",
    "\n",
    "    return threshold_values\n",
    "\n",
    "sig_counts, ref_counts = threshold_counts(\n",
    "    nv_list, sig_counts, ref_counts, None, dynamic_thresh=True\n",
    ")\n",
    "\n",
    "# Calculate the correlations\n",
    "flattened_sig_counts = [sig_counts[ind].flatten() for ind in range(num_nvs)]\n",
    "flattened_ref_counts = [ref_counts[ind].flatten() for ind in range(num_nvs)]\n",
    "\n",
    "\n",
    "num_shots = len(flattened_ref_counts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    sig_corr_coeffs = np.nan_corr_coef(flattened_sig_counts)\n",
    "    ref_corr_coeffs = np.nan_corr_coef(flattened_ref_counts)\n",
    "\n",
    "\n",
    "    diff_corr_coeffs = np.cov(flattened_sig_counts) - np.cov(flattened_ref_counts)\n",
    "\n",
    "    spin_flips = np.array([-1 if nv.spin_flip else +1 for nv in nv_list])\n",
    "    # spin_flips = np.array(\n",
    "    #     [-1 if ind in [0, 1, 4, 6] else +1 for ind in range(num_nvs)]\n",
    "    # )  # MCC\n",
    "    ideal_sig_corr_coeffs = np.outer(spin_flips, spin_flips)\n",
    "    ideal_sig_corr_coeffs = ideal_sig_corr_coeffs.astype(float)\n",
    "\n",
    "    # Replace diagonals (Cii=1) with nan so they don't show\n",
    "    vals = [sig_corr_coeffs, diff_corr_coeffs, ref_corr_coeffs, ideal_sig_corr_coeffs]\n",
    "    for val in vals:\n",
    "        np.fill_diagonal(val, np.nan)\n",
    "\n",
    "    print(np.nanmean(ref_corr_coeffs) / np.nanmean(np.abs(sig_corr_coeffs)))\n",
    "\n",
    "\n",
    "\n",
    "    # Make the colorbar symmetric about 0\n",
    "    sig_max = np.nanmax(np.abs(sig_corr_coeffs))\n",
    "    ref_max = np.nanmax(np.abs(ref_corr_coeffs))\n",
    "    diff_max = np.nanmax(np.abs(diff_corr_coeffs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    figs = []\n",
    "    titles = [\"Signal\", \"Difference\", \"Reference\", \"Ideal signal\"]\n",
    "    cbar_maxes = [sig_max, diff_max, sig_max, 1]\n",
    "    for ind in range(len(vals)):\n",
    "        coors = vals[ind]  # Replace diagonals (Cii=1) with nan so they don't show\n",
    "        np.fill_diagonal(coors, np.nan)\n",
    "        fig, ax = plt.subplots()\n",
    "        cbar_max = cbar_maxes[ind]\n",
    "        # cbar_max = 0.032\n",
    "        kpl.imshow(\n",
    "            ax,\n",
    "            vals[ind],\n",
    "            title=titles[ind],\n",
    "            cbar_label=\"Covariance\" if ind == 1 else \"Correlation coefficient\",\n",
    "            cmap=\"RdBu_r\",\n",
    "            vmin=-cbar_max,\n",
    "            vmax=cbar_max,\n",
    "            nan_color=kpl.KplColors.GRAY,\n",
    "        )\n",
    "        ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        figs.append(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of NVs\n",
    "num_nvs = len(data['nv_list'])\n",
    "# Extract reference and signal counts\n",
    "reference_counts = data['counts'][0]\n",
    "signal_counts = data['counts'][1]\n",
    "\n",
    "#Make numpy array reference and signal counts\n",
    "reference_counts = np.array(data['counts'][0])\n",
    "signal_counts = np.array(data['counts'][1])\n",
    "\n",
    "# Verify the shape of counts arrays\n",
    "print(f\"Shape of reference_counts: {reference_counts.shape}\")\n",
    "print(f\"Shape of signal_counts: {signal_counts.shape}\")\n",
    "# Flatten or reshape the counts data if needed (removing singleton dimension)\n",
    "reference_counts = np.squeeze(reference_counts)  # This removes singleton dimensions\n",
    "signal_counts = np.squeeze(signal_counts)\n",
    "# Verify the shape of counts arrays\n",
    "print(f\"Shape of reference_counts: {reference_counts.shape}\")\n",
    "print(f\"Shape of signal_counts: {signal_counts.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average over the repetitions (3rd dimension) to get a (10, 2000) array for each count\n",
    "avg_reference_counts = np.mean(reference_counts, axis=2)\n",
    "avg_signal_counts = np.mean(signal_counts, axis=2)\n",
    "# print(avg_signal_counts)\n",
    "# Threshold values\n",
    "threshold_values = np.array([nv['threshold'] for nv in data['nv_list']])\n",
    "print(threshold_values)\n",
    "# Apply thresholding to reference and signal counts\n",
    "binary_reference_counts = np.where(avg_reference_counts > threshold_values[:, None], 1, 0)\n",
    "binary_signal_counts = np.where(avg_signal_counts > threshold_values[:, None], 1, 0)\n",
    "# print(binary_signal_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute binary counts with thresholding\n",
    "def apply_thresholding(counts, thresholds):\n",
    "    return np.where(counts > thresholds[:, None], 1, 0)\n",
    "\n",
    "# Iteratively adjust threshold values to minimize correlation in reference data\n",
    "def adjust_thresholds(reference_counts, threshold_values, learning_rate=0.01, max_iterations=1000, tolerance=1e-6):\n",
    "    for iteration in range(max_iterations):\n",
    "        binary_reference_counts = apply_thresholding(reference_counts, threshold_values)\n",
    "        correlation_matrix_reference = compute_correlation_matrix(binary_reference_counts)\n",
    "        avg_correlation = np.mean(np.abs(correlation_matrix_reference[np.triu_indices(num_nvs, k=1)]))\n",
    "\n",
    "        if avg_correlation < tolerance:\n",
    "            print(f\"Convergence reached at iteration {iteration} with average correlation {avg_correlation}\")\n",
    "            break\n",
    "\n",
    "        # Adjust thresholds based on correlation matrix\n",
    "        gradient = np.sum(correlation_matrix_reference, axis=1) - np.diag(correlation_matrix_reference)\n",
    "        threshold_values -= learning_rate * gradient\n",
    "\n",
    "    return threshold_values\n",
    "\n",
    "# Adjust thresholds\n",
    "adjusted_threshold_values = adjust_thresholds(avg_reference_counts, threshold_values)\n",
    "print(f\"Adjusted threshold values: {adjusted_threshold_values}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply thresholding to reference and signal counts using adjusted thresholds\n",
    "binary_reference_counts = apply_thresholding(avg_reference_counts, adjusted_threshold_values)\n",
    "binary_signal_counts = apply_thresholding(avg_signal_counts, adjusted_threshold_values)\n",
    "\n",
    "\n",
    "# Compute correlation matrices for shot-to-shot correlations\n",
    "correlation_matrix_reference = compute_correlation_matrix(binary_reference_counts)\n",
    "correlation_matrix_signal = compute_correlation_matrix(binary_signal_counts)\n",
    "\n",
    "# Set the range for the colormap\n",
    "vmin = -0.1\n",
    "vmax = 0.2\n",
    "\n",
    "# Plot correlation matrix for reference counts\n",
    "# plt.imshow(correlation_matrix_reference, cmap='bwr', interpolation='nearest', vmin=vmin, vmax=vmax)\n",
    "# Replace diagonal elements with gray color\n",
    "np.fill_diagonal(correlation_matrix_reference, np.nan)  # Replace diagonal elements with NaN\n",
    "plt.imshow(correlation_matrix_reference, cmap='bwr', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.title('Correlation Matrix (Reference Counts)')\n",
    "plt.show()\n",
    "\n",
    "# Plot correlation matrix for signal counts\n",
    "np.fill_diagonal(correlation_matrix_signal,np.nan)\n",
    "plt.imshow(correlation_matrix_signal, cmap='bwr', interpolation='nearest', vmin=vmin, vmax=vmax)\n",
    "plt.colorbar()\n",
    "plt.title('Correlation Matrix (Signal Counts)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed data\n",
    "output_dir = '../data/processed'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "output_path_reference = os.path.join(output_dir, 'processed_binary_reference_counts.npy')\n",
    "output_path_signal = os.path.join(output_dir, 'processed_binary_signal_counts.npy')\n",
    "\n",
    "np.save(output_path_reference, binary_reference_counts)\n",
    "np.save(output_path_signal, binary_signal_counts)\n",
    "\n",
    "print(f\"Processed binary reference counts saved to: {output_path_reference}\")\n",
    "print(f\"Processed binary signal counts saved to: {output_path_signal}\")\n",
    "\n",
    "# Save the correlation matrices\n",
    "correlation_matrix_path_reference = os.path.join(output_dir, 'correlation_matrix_reference.npy')\n",
    "correlation_matrix_path_signal = os.path.join(output_dir, 'correlation_matrix_signal.npy')\n",
    "\n",
    "np.save(correlation_matrix_path_reference, correlation_matrix_reference)\n",
    "np.save(correlation_matrix_path_signal, correlation_matrix_signal)\n",
    "\n",
    "print(f\"Correlation matrix for reference counts saved to: {correlation_matrix_path_reference}\")\n",
    "print(f\"Correlation matrix for signal counts saved to: {correlation_matrix_path_signal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute correlation matrices for shot-to-shot correlations\n",
    "correlation_matrix_reference = compute_correlation_matrix(binary_reference_counts)\n",
    "correlation_matrix_signal = compute_correlation_matrix(binary_signal_counts)\n",
    "\n",
    "# Plot correlation matrices\n",
    "plt.imshow(correlation_matrix_reference, cmap='bwr', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.title('Correlation Matrix (Reference Counts)')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(correlation_matrix_signal, cmap='bwr', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.title('Correlation Matrix (Signal Counts)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output directory\n",
    "output_dir = '../data/correlation_matrix'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Save correlation matrices\n",
    "np.save(os.path.join(output_dir, 'correlation_matrix_reference.npy'), correlation_matrix_reference)\n",
    "np.save(os.path.join(output_dir, 'correlation_matrix_signal.npy'), correlation_matrix_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute correlation matrices\n",
    "correlation_matrix_reference = np.corrcoef(averaged_reference_counts)\n",
    "correlation_matrix_signal = np.corrcoef(averaged_signal_counts)\n",
    "\n",
    "# Plot resized correlation matrices\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "cax0 = axs[0].imshow(correlation_matrix_reference, cmap='hot', interpolation='nearest')\n",
    "axs[0].set_title('Reference Counts Correlation Matrix')\n",
    "axs[0].set_xlabel('NVs')\n",
    "axs[0].set_ylabel('NVs')\n",
    "fig.colorbar(cax0, ax=axs[0])\n",
    "\n",
    "cax1 = axs[1].imshow(correlation_matrix_signal, cmap='hot', interpolation='nearest')\n",
    "axs[1].set_title('Signal Counts Correlation Matrix')\n",
    "axs[1].set_xlabel('NVs')\n",
    "axs[1].set_ylabel('NVs')\n",
    "fig.colorbar(cax1, ax=axs[1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold values\n",
    "threshold_values = np.array([nv['threshold'] for nv in data['nv_list']])\n",
    "# Apply thresholding to reference and signal counts\n",
    "binary_reference_counts = np.where(averaged_reference_counts > threshold_values[:, None], 1, 0)\n",
    "binary_signal_counts = np.where(averaged_signal_counts > threshold_values[:, None], 1, 0)\n",
    "print(binary_reference_counts)\n",
    "print(binary_reference_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute correlation matrices\n",
    "correlation_matrix_reference = np.corrcoef(binary_reference_counts)\n",
    "correlation_matrix_signal = np.corrcoef(binary_signal_counts)\n",
    "\n",
    "# Plot resized correlation matrices\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "cax0 = axs[0].imshow(correlation_matrix_reference, cmap='hot', interpolation='nearest')\n",
    "axs[0].set_title('Reference Counts Correlation Matrix')\n",
    "axs[0].set_xlabel('NVs')\n",
    "axs[0].set_ylabel('NVs')\n",
    "fig.colorbar(cax0, ax=axs[0])\n",
    "\n",
    "cax1 = axs[1].imshow(correlation_matrix_signal, cmap='hot', interpolation='nearest')\n",
    "axs[1].set_title('Signal Counts Correlation Matrix')\n",
    "axs[1].set_xlabel('NVs')\n",
    "axs[1].set_ylabel('NVs')\n",
    "fig.colorbar(cax1, ax=axs[1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output directory\n",
    "output_dir = '../data/correlation_matrix'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Save correlation matrices\n",
    "np.save(os.path.join(output_dir, 'correlation_matrix_reference.npy'), correlation_matrix_reference)\n",
    "np.save(os.path.join(output_dir, 'correlation_matrix_signal.npy'), correlation_matrix_signal)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
